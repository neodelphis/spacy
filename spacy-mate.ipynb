{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233ba49a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# spaCy\n",
    "\n",
    "[Tuto@Mate ‚Äì 19 mai 2022 - Cl√©ment Plancq (MSH Val de Loire ‚Äì CITERES)](https://www.youtube.com/watch?v=Z58g33GglR0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fa730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. **Introduction**\n",
    "2. √âtapes de la cha√Æne de traitement\n",
    "3. Extraction d'information\n",
    "4. Adaptation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15396ff9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# spaCy qu√©saco ?\n",
    "\n",
    "https://spacy.io/\n",
    "\n",
    "- ~~logiciel~~\n",
    "- ~~application~~\n",
    "- ~~service web~~\n",
    "- biblioth√®que logicielle (*library*, *lib*),\n",
    "- √©crite en Python (et Cython),\n",
    "- pour le TAL (*NLP*)\n",
    "- sous licence libre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6433e6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# spaCy qu√©saco ?\n",
    "\n",
    "- Produit de la soci√©t√© [explosion.ai](https://explosion.ai/)  \n",
    "fond√©e par : Matthew Honnibal ([@honnibal](https://twitter.com/honnibal)) et Ines Montani ([@_inesmontani](https://twitter.com/_inesmontani))\n",
    "- Licence MIT (Open Source) pour le code\n",
    "    - Licences ouvertes diverses pour les mod√®les\n",
    "- Projet d√©marr√© en 2015, v1.0.0 en octobre 2016, v3.3.0 ([github](https://github.com/explosion/spaCy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fe44d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# spaCy qu√©saco ?\n",
    "\n",
    "- Outil destin√© √† √™tre utilis√© en production : \n",
    "    - rapide\n",
    "    - stable\n",
    "    - qualit√© du code (tests, documentation, packaging)\n",
    "    \n",
    "- **MAIS** pas de choix de la m√©thode ou de l'algorithme utilis√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7329c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# spaCy qu√©saco ?\n",
    "\n",
    "- Cha√Æne de traitements de TAL\n",
    "    - tokenisation (*tokenizer*)\n",
    "    - √©tiquetage POS (*tagger*)\n",
    "    - analyse syntaxique (*parser*)\n",
    "    - d√©tection d'entit√©s nomm√©es (*ner*)\n",
    "    - lemmatisation\n",
    "    - (cat√©gorisation de texte\n",
    "    - word embedding)\n",
    "- Usage de mod√®les statistiques (m√©thodes neuronales)\n",
    "- Int√©gration possible de mod√®les tiers (PyTorch ou TensorFlow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeeab83",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pourquoi spaCy ?\n",
    "\n",
    "- C'est du Python ü•≥  \n",
    "<small>Il existe un wrapper R, voir [ici](https://spacyr.quanteda.io/)</small>\n",
    "- Plut√¥t simple √† prendre en main\n",
    "- Tr√®s bien document√© ([doc](https://spacy.io/usage), [api](https://spacy.io/api)) <small>D'ailleurs plut√¥t que ce notebook, suivez l'excellent tutoriel d'Ines Montani : [https://course.spacy.io/](https://course.spacy.io/)</small>\n",
    "- Cyle de d√©veloppement/release r√©gulier, suivi de la communaut√© sur GitHub (discussions, issues)\n",
    "- Ressources construites avec spaCy :¬†https://spacy.io/universe\n",
    "\n",
    "\n",
    "- Fournit les m√©thodes et les moyens d'adapter le traitement et/ou le mod√®le √† des besoins particuliers\n",
    "- **MAIS** ce n'est pas forc√©ment l'outil qui donne les meilleurs r√©sultats pour le fran√ßais dans toutes les t√¢ches de TAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37e71a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# spaCy et les autres\n",
    "\n",
    "spaCy est *un* des frameworks de TAL disponibles\n",
    "\n",
    "- [NLTK](http://www.nltk.org/) : python, orient√© p√©dagogie, choix des m√©thodes et algos √† utiliser\n",
    "- [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) :¬†java, framework de Stanford, orient√© recherche, cha√Æne de TAL¬†tr√®s compl√®te pour l'anglais en particulier\n",
    "- [Stanza](https://stanfordnlp.github.io/stanza/) : python, framework de Stanford, mod√®les neuronaux entra√Æn√©s sur les donn√©es d'Universal Dependancies <small>[https://github.com/explosion/spacy-stanza](https://github.com/explosion/spacy-stanza) permet d'utiliser les mod√®les de Stanford avec Spacy</small>\n",
    "- [TextBlob](https://textblob.readthedocs.io/en/dev/) : python\n",
    "- [DKPro](https://dkpro.github.io) :¬†java\n",
    "- [flair](https://github.com/zalandoresearch/flair) : python, le framework de Zalando, tr√®s bonnes performances en reconnaissance d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb59bf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les mod√®les de spaCy\n",
    "\n",
    "- Spacy utilise des [mod√®les statistiques](https://spacy.io/models) qui permettent de pr√©dire des annotations linguistiques\n",
    "- 21 langues : allemand, anglais, catalan, chinois, cor√©en, danois, espagnol, finnois, fran√ßais, italien, japonais, lituanien, mac√©donien, n√©erlandais, grec, norv√©gien, polonais, portugais, roumain, russe, su√©dois + mod√®le multi langues\n",
    "\n",
    "\n",
    "- Tous ces mod√®les, quelque soient leur type ou leur langue, s'utilisent de la m√™me fa√ßon, avec la m√™me API\n",
    "- La justesse des annotations d√©pendra en grande partie de la proximit√© entre le texte soumis et les textes du corpus d'entra√Ænement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c0bbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les mod√®les pour le fran√ßais\n",
    "\n",
    "- 4 mod√®les pour le fran√ßais\n",
    "    - [fr_core_news_sm](https://spacy.io/models/fr#fr_core_news_sm) (tagger, morphologizer, lemmatizer, parser, ner) 15‚ÄØMo \n",
    "    - [fr_core_news_md](https://spacy.io/models/fr#fr_core_news_md) (tagger, morphologizer, lemmatizer, parser, ner, vectors) 43‚ÄØMo\n",
    "    - [fr_core_news_lg](https://spacy.io/models/fr#fr_core_news_lg) (tagger, morphologizer, lemmatizer, parser, ner, vectors) 545‚ÄØMo\n",
    "    - [fr_dep_news_trf](https://spacy.io/models/fr#fr_dep_news_trf) (tagger, morphologizer, lemmatizer, parser) 382‚ÄØMo\n",
    "- mod√®les `fr` appris sur les corpus [Sequoia](https://deep-sequoia.inria.fr/fr/) et [WikiNer](https://figshare.com/articles/Learning_multilingual_named_entity_recognition_from_Wikipedia/5462500)\n",
    "- sauf le mod√®le `trf` qui est issu de camembert-base distribu√© par [Hugging Face](https://huggingface.co/camembert-base), entra√Æn√© sur [Oscar](https://oscar-corpus.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48e661",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Introduction\n",
    "2. **√âtapes de la cha√Æne de traitement**\n",
    "3. Extraction d'information\n",
    "4. Adaptation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab02ae-5499-4f39-9995-c76a8f9c33cc",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```sh\n",
    "conda create -n nlp python=3.10\n",
    "conda activate nlp\n",
    "conda install pytorch torchvision -c pytorch\n",
    "conda install -c conda-forge jupyterlab\n",
    "conda install ipykernel\n",
    "ipython kernel install --user --name=nlp\n",
    "conda install spacy\n",
    "python -m spacy download fr_dep_news_trf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f4dc9-2921-416d-a5d3-565017f224dc",
   "metadata": {},
   "source": [
    "## Test installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad19598-6428-4c76-83c5-bdc8138c8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3756, 0.2839, 0.5497],\n",
      "        [0.2422, 0.9713, 0.0489],\n",
      "        [0.5721, 0.2401, 0.9111],\n",
      "        [0.9373, 0.6879, 0.2090],\n",
      "        [0.2563, 0.5584, 0.1588]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261ee025-8f93-47b0-af0f-2f2e6510f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"C'\", 'PRON'), ('est', 'AUX'), ('une', 'DET'), ('phrase', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_dep_news_trf\")\n",
    "doc = nlp(\"C'est une phrase.\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa153028-4f9a-4219-a515-13b0ccdae624",
   "metadata": {},
   "source": [
    "[Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fba35c36-c9c6-4f99-909d-5d6ffdebd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc429d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tok√©nisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07047980",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_dep_news_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9405efd2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et\n",
      "tu\n",
      "recherches\n",
      "dans\n",
      "le\n",
      "vague\n",
      "une\n",
      "ombre\n",
      ",\n",
      "un\n",
      "sourire\n",
      "qui\n",
      "soulage\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Et tu recherches dans le vague une ombre, un sourire qui soulage.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14221974",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La tok√©nisation est non destructive. On peut d√©couper un texte en tokens et le restituer dans sa forme originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c7c580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dictionnaire de mes souvenirs\n",
      "N'a qu'une page, une seule rubrique\n",
      "Qui commence par ton absence\n",
      "Et dans l'ordre alphab√©tique\n",
      "Se termine par l'√©tat d'amn√©sie\n",
      "Tes √©tats d'√¢me sont un leurre\n",
      "Et tes larmes sont les armes dont tu te sers\n",
      "Mais ce pi√®ge ne tromperait qu'un amateur\n",
      "Ton √¢me s≈ìur est une meilleure adversaire\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Le dictionnaire de mes souvenirs\n",
    "N'a qu'une page, une seule rubrique\n",
    "Qui commence par ton absence\n",
    "Et dans l'ordre alphab√©tique\n",
    "Se termine par l'√©tat d'amn√©sie\n",
    "Tes √©tats d'√¢me sont un leurre\n",
    "Et tes larmes sont les armes dont tu te sers\n",
    "Mais ce pi√®ge ne tromperait qu'un amateur\n",
    "Ton √¢me s≈ìur est une meilleure adversaire\"\"\")\n",
    "\n",
    "\n",
    "# All tokens in spacy keep their context around so all text can be recreated without any loss of data.\n",
    "# Since the attribute text_with_ws has the token with its corresponding whitespace character if it exists.\n",
    "text = ''.join([token.text_with_ws for token in doc])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d815a7f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un objet de la classe [`Doc`](https://spacy.io/api/doc) contient aussi le produit du d√©coupage en phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8fedb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C‚Äô√©tait pas l'ann√©e derni√®re. \n",
      "\n",
      "C'√©tait pas √† Marienbad. \n",
      "\n",
      "Comment voulez-vous que je m'en rappelle, √† force de l'attendre, je ne savais plus qui l'attendait. \n",
      "\n",
      "Le temps est un tra√Ætre de cape et d'√©p√©e qui vous glisse sa poudre d'oubli dans votre coca. \n",
      "\n",
      "Faudrait pouvoir choisir son film. \n",
      "\n",
      "J'n'avais plus qu'√† me barricader dans la p'tite maison pr√®s du lac avec le cano√´ rose, √† deux places qui flotterait, comme √ßa pour personne \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"C‚Äô√©tait pas l'ann√©e derni√®re. C'√©tait pas √† Marienbad. \\\n",
    "Comment voulez-vous que je m'en rappelle, √† force de l'attendre, \\\n",
    "je ne savais plus qui l'attendait. Le temps est un tra√Ætre de cape et d'√©p√©e \\\n",
    "qui vous glisse sa poudre d'oubli dans votre coca. Faudrait pouvoir choisir son film. \\\n",
    "J'n'avais plus qu'√† me barricader dans la p'tite maison pr√®s du lac \\\n",
    "avec le cano√´ rose, √† deux places qui flotterait, comme √ßa pour personne\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4442478",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## √âtiquetage (*tagging*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b02aa-c0ae-4be2-88d1-b25a00fd8f62",
   "metadata": {},
   "source": [
    "[Part-of-speech tagging](https://spacy.io/usage/linguistic-features#pos-tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b04d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous PUNCT\n",
      "mes PUNCT\n",
      "beaux PUNCT\n",
      "ch√¢teaux PUNCT\n",
      "d' PUNCT\n",
      "√âquateur PUNCT\n",
      "s' PUNCT\n",
      "√©croulent PUNCT\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tous mes beaux ch√¢teaux d'√âquateur s'√©croulent.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, tok.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ee3e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Les annotations portant sur les tokens sont accessibles via les attributs des objets de type `token`‚ÄØ: [https://spacy.io/api/token#attributes](https://spacy.io/api/token#attributes)  \n",
    "  - `pos_` contient l'√©tiquette de partie du discours de [universal dependancies](https://universaldependencies.org/docs/u/pos/)\n",
    "  - `tag_` contient l'√©tiquette du corpus original, parfois plus d√©taill√©e\n",
    "  - `lemma_` pour le lemme\n",
    "  - `morph` pour l'analyse morphologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35199e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous tout ADJ Gender=Masc|Number=Plur\n",
      "mes mon DET Number=Plur|Poss=Yes\n",
      "beaux beal ADJ Gender=Masc|Number=Plur\n",
      "ch√¢teaux ch√¢teau NOUN Gender=Masc|Number=Plur\n",
      "d' de ADP \n",
      "√âquateur √âquateur PROPN Gender=Masc|Number=Sing\n",
      "s' se PRON Person=3|Reflex=Yes\n",
      "√©croulent √©crouler VERB Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
      ". . PUNCT \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.lemma_, token.pos_, token.morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb97fd1-6f7e-4403-aa07-9258d0149aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Shape</th>\n",
       "      <th>alpha</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tous</td>\n",
       "      <td>tout</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mes</td>\n",
       "      <td>mon</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beaux</td>\n",
       "      <td>beal</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch√¢teaux</td>\n",
       "      <td>ch√¢teau</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d'</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>x'</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>√âquateur</td>\n",
       "      <td>√âquateur</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s'</td>\n",
       "      <td>se</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>expl:comp</td>\n",
       "      <td>x'</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>√©croulent</td>\n",
       "      <td>√©crouler</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text     Lemma    POS    Tag        Dep  Shape  alpha   stop\n",
       "0       Tous      tout    ADJ    ADJ       amod   Xxxx   True   True\n",
       "1        mes       mon    DET    DET        det    xxx   True   True\n",
       "2      beaux      beal    ADJ    ADJ       amod   xxxx   True  False\n",
       "3   ch√¢teaux   ch√¢teau   NOUN   NOUN      nsubj   xxxx   True  False\n",
       "4         d'        de    ADP    ADP       case     x'  False   True\n",
       "5   √âquateur  √âquateur  PROPN  PROPN       nmod  Xxxxx   True  False\n",
       "6         s'        se   PRON   PRON  expl:comp     x'  False   True\n",
       "7  √©croulent  √©crouler   VERB   VERB       ROOT   xxxx   True  False\n",
       "8          .         .  PUNCT  PUNCT      punct      .  False  False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tags = ['Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'alpha', 'stop']\n",
    "d = {tag:[] for tag in tags}\n",
    "\n",
    "doc = nlp(\"Tous mes beaux ch√¢teaux d'√âquateur s'√©croulent.\")\n",
    "\n",
    "for token in doc:\n",
    "    d['Text'].append(token.text)\n",
    "    d['Lemma'].append(token.lemma_)\n",
    "    d['POS'].append(token.pos_)\n",
    "    d['Tag'].append(token.tag_)\n",
    "    d['Dep'].append(token.dep_)\n",
    "    d['Shape'].append(token.shape_)\n",
    "    d['alpha'].append(token.is_alpha)\n",
    "    d['stop'].append(token.is_stop)\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d60eb-9573-4a9c-ad13-efd41002a197",
   "metadata": {},
   "source": [
    "    Text: The original word text.\n",
    "    Lemma: The base form of the word.\n",
    "    POS: The simple UPOS part-of-speech tag.\n",
    "    Tag: The detailed part-of-speech tag.\n",
    "    Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "    Shape: The word shape ‚Äì capitalization, punctuation, digits.\n",
    "    is alpha: Is the token an alpha character?\n",
    "    is stop: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f86c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## D√©tection d'entit√©s nomm√©es (*ner : Named Entity Recognition*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ba718f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mister Kali Jones PER\n",
      "Bill Ballantine PER\n",
      "Cara√Øbes LOC\n"
     ]
    }
   ],
   "source": [
    "# Avec fr_dep_news_trf\n",
    "#UserWarning: [W006] No entities to visualize found in Doc object.\n",
    "# If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition,\n",
    "#and check the `doc.ents` property manually if necessary.\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "doc = nlp(\"Le bandit s'appelle Mister Kali Jones \\\n",
    "avec l'ami Bill Ballantine, \\\n",
    "sauv√© de justesse des crocodiles, \\\n",
    "stop au trafic des Cara√Øbes.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531347bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Le bandit s'appelle \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mister Kali Jones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " avec l'ami \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill Ballantine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", sauv√© de justesse des crocodiles, stop au trafic des \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cara√Øbes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54903ec6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">√Ä l‚Äôheure o√π le pr√©sident russe, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vladimir Poutine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", pronon√ßait sur la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    place Rouge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " son discours annuel sur la guerre de 1941-1945, cette ann√©e presque enti√®rement consacr√©e au conflit en \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ukraine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", son homologue ukrainien, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Volodymyr Zelensky\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", diffusait une vid√©o de lui-m√™me marchant seul sur l'avenue Khrechtchatyk de Kiev, l√† o√π ont lieu, d‚Äôhabitude, les c√©r√©monies nationales dans son pays.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"√Ä l‚Äôheure o√π le pr√©sident russe, Vladimir Poutine, pronon√ßait sur la place Rouge son discours annuel \\\n",
    "sur la guerre de 1941-1945, cette ann√©e presque enti√®rement consacr√©e au conflit en Ukraine, \\\n",
    "son homologue ukrainien, Volodymyr Zelensky, diffusait une vid√©o de lui-m√™me marchant seul \\\n",
    "sur l'avenue Khrechtchatyk de Kiev, l√† o√π ont lieu, d‚Äôhabitude, les c√©r√©monies nationales dans son pays.\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff699fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Analyse syntaxique (*parsing*)\n",
    "\n",
    " - L'analyse syntaxique ou *parsing* de Spacy est une analyse en d√©pendance.\n",
    "\n",
    "- Dans l'analyse en d√©pendance produite par Spacy, chaque mot d'une phrase a un gouverneur unique (*head*), la relation de d√©pendance entre le mot et son gouverneur est typ√©e (*nsubj*, *obj*, ‚Ä¶).  \n",
    "Pour la t√™te de la phrase on utilise la relation *ROOT*.\n",
    "\n",
    "- La structure produite par l'analyse syntaxique est un arbre, un graphe acyclique et connexe.  \n",
    "Les tokens sont les n≈ìuds, les arcs sont les d√©pendances, le type de la relation est l'√©tiquette de l'arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "818cd281",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il expl:subj refile\n",
      "te iobj refile\n",
      "refile ROOT refile\n",
      "en case chanson\n",
      "st√©r√©o fixed en\n",
      "la det chanson\n",
      "chanson obl:arg refile\n",
      "des case sir√®nes\n",
      "sir√®nes nmod chanson\n",
      ". punct refile\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Il te refile en st√©r√©o la chanson des sir√®nes.\")\n",
    "for token in doc:\n",
    "    print(token, token.dep_, token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0072ef85",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"66ab814b65dd4e738de717a7e08e4f10-0\" class=\"displacy\" width=\"1040\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Il</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">te</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">refile</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">st√©r√©o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">chanson</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">des</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">sir√®nes.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,57.0 265.0,57.0 265.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">expl:subj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,112.0 260.0,112.0 260.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">iobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L172,157.0 188,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-2\" stroke-width=\"2px\" d=\"M400,167.0 C400,57.0 705.0,57.0 705.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-3\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">fixed</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,169.0 L488.0,157.0 472.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-4\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,169.0 L612,157.0 628,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-5\" stroke-width=\"2px\" d=\"M290,167.0 C290,2.0 710.0,2.0 710.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:arg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M710.0,169.0 L718.0,157.0 702.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66ab814b65dd4e738de717a7e08e4f10-0-7\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66ab814b65dd4e738de717a7e08e4f10-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,169.0 L933.0,157.0 917.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(\"Il te refile en st√©r√©o la chanson des sir√®nes.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2cd4b3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep tree   Token   Dep type  Lemma   Part of Sp\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "      ‚îå‚îÄ‚îÄ‚ñ∫ Il      expl:subj il      PRON      \n",
      "      ‚îÇ‚îå‚îÄ‚ñ∫ te      iobj      te      PRON      \n",
      "‚îå‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚î¥‚îÄ‚îÄ refile  ROOT      refiler VERB      \n",
      "‚îÇ‚îÇ  ‚îå‚îÄ‚ñ∫‚îå‚îÄ‚îÄ en      case      en      ADP       \n",
      "‚îÇ‚îÇ  ‚îÇ  ‚îî‚îÄ‚ñ∫ st√©r√©o  fixed     st√©r√©o  ADJ       \n",
      "‚îÇ‚îÇ  ‚îÇ  ‚îå‚îÄ‚ñ∫ la      det       le      DET       \n",
      "‚îÇ‚îî‚îÄ‚ñ∫‚îú‚îÄ‚îÄ‚î¥‚îÄ‚îÄ chanson obl:arg   chanson NOUN      \n",
      "‚îÇ   ‚îÇ  ‚îå‚îÄ‚ñ∫ des     case      de      ADP       \n",
      "‚îÇ   ‚îî‚îÄ‚ñ∫‚îî‚îÄ‚îÄ sir√®nes nmod      sir√®ne  NOUN      \n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ .       punct     .       PUNCT     \n"
     ]
    }
   ],
   "source": [
    "import explacy\n",
    "# https://spacy.io/universe/project/explacy\n",
    "\n",
    "explacy.print_parse_info(nlp, \"Il te refile en st√©r√©o la chanson des sir√®nes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2507826",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Les attributs de token suivants peuvent √™tre utilis√©s pour parcourir l'arbre de d√©pendance : \n",
    "- `children` les tokens d√©pendants du token\n",
    "- `subtree` tous les descendants du token\n",
    "- `ancestors` tous les parents du token\n",
    "- `rights` les enfants √† droite du token\n",
    "- `lefts` les enfants √† gauche du token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844282ed-d218-4aa4-ac6e-ab0c2f2fdc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il expl:subj refile VERB []\n",
      "te iobj refile VERB []\n",
      "refile ROOT refile VERB [Il, te, chanson, .]\n",
      "en case chanson NOUN [st√©r√©o]\n",
      "st√©r√©o fixed en ADP []\n",
      "la det chanson NOUN []\n",
      "chanson obl:arg refile VERB [en, la, sir√®nes]\n",
      "des case sir√®nes NOUN []\n",
      "sir√®nes nmod chanson NOUN [des]\n",
      ". punct refile VERB []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8eaece1d-f4b3-4a8b-8f22-fcbafe71073f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "refile"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = [token for token in doc if token.head == token][0]\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18e8ba6d-4ae3-425e-9fc2-4af2320e5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Il', 'te']\n",
      "['chanson', '.']\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in root.lefts])  # ['bright', 'red']\n",
    "print([token.text for token in root.rights])  # ['on']\n",
    "print(doc[2].n_lefts)  # 2\n",
    "print(doc[2].n_rights)  # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eabfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Introduction\n",
    "2. √âtapes de la cha√Æne de traitement\n",
    "3. **Extraction d'information**\n",
    "4. Adaptation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7fe20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## r√®gles sur les tokens\n",
    "\n",
    "- Spacy a une classe `Matcher` qui permet de rep√©rer des tokens ou des s√©quences de tokens √† l'aide de patrons (*pattern*).\n",
    "\n",
    "- Ces patrons peuvent porter sur la forme des tokens ou leurs attributs (pos, ent, ‚Ä¶).  \n",
    "\n",
    "- On peut aussi utiliser des cat√©gories comme `IS_ALPHA` ou `IS_NUM`, voir la [doc](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)\n",
    "\n",
    "- (Il existe une [d√©mo](https://explosion.ai/demos/matcher) avec interface graphique mais pas pour le fran√ßais üôÅ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3720989",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc[5, 8] = \"en taille XL\"\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "doc = nlp(\"Ce mod√®le est aussi disponible en taille XL ; je vous le conseille.\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "# 'en' 'taille' + lettres en maj\n",
    "matcher.add(\"tailles\", [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "for x, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(f\"doc[{start}, {end}] = \\\"{span.text}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b26a6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "√áa fonctionne pour les s√©quences comme ¬´ en taille M ¬ª ou ¬´ en taille XL ¬ª mais pas pour ¬´ vous l'avez en XL ? ¬ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e5338a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(f\"doc[{start}, {end}] = \\\"{span.text}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077f1d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut essayer d'am√©liorer les r√®gles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05e71254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc[3, 5] = \"en XL\"\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# r√®gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(f\"doc[{start}, {end}] = \\\"{span.text}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af0157c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ou encore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63dcc25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc[3, 5] = \"en XL\"\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "sizes = ['XS', 'S', 'M', 'L', 'XL']\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# r√®gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(f\"doc[{start}, {end}] = \\\"{span.text}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917e09",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Entit√©s nomm√©es : traitement par r√®gles\n",
    "\n",
    "Voir [https://spacy.io/usage/rule-based-matching#entityruler](https://spacy.io/usage/rule-based-matching#entityruler)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdc560cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "histoire_da = \"\"\"Val√©rie s'ennuyait\n",
    "Dans les bras de Nicolas \n",
    "Mais Nicolas, celui-l√† \n",
    "Ne le savait pas \n",
    "Isabelle a attendu, attendu \n",
    "Mais Patrick n'est jamais reparu \n",
    "\n",
    "Les histoires d'A \n",
    "Les histoires d'amour \n",
    "Les histoires d'amour finissent mal \n",
    "Les histoires d'amour finissent mal en g√©n√©ral \n",
    "\n",
    "Michel aimait G√©rard \n",
    "Et G√©rard le lui rendait si bien \n",
    "Qu'√† la fin √ßa ne rendait rien \n",
    "Evelyne toute sa vie attendit \n",
    "Que le monsieur en gris lui sourit \n",
    "\n",
    "Gilbert partit en voyage \n",
    "Juste au moment de son mariage \n",
    "Hector est mort en faisant une fugue \n",
    "Il allait retrouver Gertrude \n",
    "Simone et Tom s'engueulaient \n",
    "D√®s que vingt et une heures sonnaient \n",
    "\n",
    "Les histoires d'amour finissent mal en g√©n√©ral \n",
    "Les histoires d'amour finissent mal en g√©n√©ral \n",
    "Les histoires d'amour finissent mal en g√©n√©ral \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3e00ea1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Val√©rie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " s'ennuyait<br>Dans les bras de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nicolas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>Mais \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nicolas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", celui-l√† <br>Ne le savait pas <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Isabelle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " a attendu, attendu <br>Mais \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Patrick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " n'est jamais reparu <br><br>Les histoires d'\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "Les histoires d'amour <br>Les histoires d'amour finissent mal <br>Les histoires d'amour finissent mal en g√©n√©ral <br><br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " aimait \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    G√©rard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>Et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    G√©rard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " le lui rendait si bien <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Qu'√† la fin √ßa ne rendait rien \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Evelyne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " toute sa vie attendit <br>Que le monsieur en gris lui sourit <br><br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gilbert\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " partit en voyage <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Juste au moment de son mariage \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hector\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " est mort en faisant une fugue <br>Il allait retrouver \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gertrude\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Simone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tom\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " s'engueulaient <br>D√®s que vingt et une heures sonnaient <br><br>Les histoires d'amour finissent mal en g√©n√©ral <br>Les histoires d'amour finissent mal en g√©n√©ral <br>Les histoires d'amour finissent mal en g√©n√©ral </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(histoire_da)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea2c3550-eb0b-484f-8ae7-57c9184f5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Val√©rie', 'PER'), ('Nicolas', 'PER'), ('Nicolas', 'PER'), ('Isabelle', 'PER'), ('Patrick', 'PER'), ('Michel', 'PER'), ('G√©rard', 'PER'), ('G√©rard', 'PER'), ('Evelyne', 'PER'), ('Gilbert', 'PER'), ('Hector', 'PER'), ('Gertrude', 'PER'), ('Simone', 'PER'), ('Tom', 'PER')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Val√©rie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " s'ennuyait<br>Dans les bras de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nicolas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>Mais \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nicolas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", celui-l√† <br>Ne le savait pas <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Isabelle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " a attendu, attendu <br>Mais \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Patrick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " n'est jamais reparu <br><br>Les histoires d'A <br>Les histoires d'amour <br>Les histoires d'amour finissent mal <br>Les histoires d'amour finissent mal en g√©n√©ral <br><br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " aimait \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    G√©rard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>Et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    G√©rard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " le lui rendait si bien <br>Qu'√† la fin √ßa ne rendait rien <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Evelyne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " toute sa vie attendit <br>Que le monsieur en gris lui sourit <br><br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gilbert\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " partit en voyage <br>Juste au moment de son mariage <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hector\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " est mort en faisant une fugue <br>Il allait retrouver \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gertrude\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " <br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Simone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tom\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " s'engueulaient <br>D√®s que vingt et une heures sonnaient <br><br>Les histoires d'amour finissent mal en g√©n√©ral <br>Les histoires d'amour finissent mal en g√©n√©ral <br>Les histoires d'amour finissent mal en g√©n√©ral </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "nlp = spacy.load('fr_core_news_lg', disable = ['ner'])\n",
    "\n",
    "first_names = [\"Val√©rie\", \"Nicolas\", \"Isabelle\", \"Patrick\", \"Michel\", \"G√©rard\",\\\n",
    "           \"Evelyne\", \"Gilbert\", \"Hector\", \"Gertrude\", \"Simone\", \"Tom\"]\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"PER\", \"pattern\":[{\"TEXT\": {\"IN\": first_names}}]}]\n",
    "#for f in first_names:\n",
    "#    ruler.add_patterns([{\"label\": \"PER\", \"pattern\": f}])\n",
    "    \n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(histoire_da)\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbff2f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dependency Matcher : extraction de patrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777737d",
   "metadata": {},
   "source": [
    "- Depuis la v3, Spacy a ajout√© un *Dependancy Matcher* qui permet de faire de l'extraction de patrons syntaxiques\n",
    "\n",
    "- Il est maintenant possible de faire porter des requ√™tes sur l'arbre syntaxique et non plus seulement sur la s√©quence des tokens.  \n",
    "\n",
    "- Ce dispositif utilise [Semgrex](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html), la syntaxe utilis√©e dans Tgrep et Tregex, les outils de requ√™te sur Treebank de Stanford.\n",
    "\n",
    "- Voir la [documentation](https://spacy.io/usage/rule-based-matching#dependencymatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49f87c13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ventre_short = \"\"\n",
    "with open('Le_Ventre_de_Paris-short.txt') as input_f:\n",
    "    ventre_short = input_f.read()\n",
    "doc = nlp(ventre_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e48c5e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vend\n",
      "vendant\n",
      "vendait\n",
      "vends\n",
      "vendait\n",
      "vendaient\n",
      "vendaient\n",
      "vend\n",
      "vendu\n",
      "vendu\n",
      "vendre\n",
      "vendait\n",
      "vendu\n",
      "vendais\n",
      "vendu\n",
      "vendrait\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "  {\n",
    "    \"RIGHT_ID\": \"vendre\",    \n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": \"vendre\"}\n",
    "  }\n",
    "]\n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, token_ids in matches:\n",
    "    for token_id in token_ids:\n",
    "        print(doc[token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe5fc967",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbe, sujet, objet :  acheta -> il -> derniers\n",
      "objet complet :  ses deux derniers sous de pain\n",
      "Phrase compl√©te :  Mais, √† Vernon, il acheta ses deux derniers sous de pain.\n",
      "\n",
      "verbe, sujet, objet :  achetait -> elle -> navets\n",
      "objet complet :  ses navets √† mon p√®re\n",
      "Phrase compl√©te :  J‚Äô√©tais gamine, qu‚Äôelle achetait d√©j√† ses navets √† mon p√®re.\n",
      "\n",
      "verbe, sujet, objet :  vendaient -> qui -> bottes\n",
      "objet complet :  des bottes de foug√®re et des paquets de feuilles de vigne , bien r√©guliers , attach√©s par quarterons\n",
      "Phrase compl√©te :  Ils s‚Äôarr√™t√®rent curieusement devant des femmes qui vendaient des bottes de foug√®re et des paquets de feuilles de vigne, bien r√©guliers, attach√©s par quarterons.\n",
      "\n",
      "verbe, sujet, objet :  vend -> Lui -> volaille\n",
      "objet complet :  toute la volaille qu‚Äô il veut\n",
      "Phrase compl√©te :  Lui, vend toute la volaille qu‚Äôil veut‚Ä¶\n",
      "\n",
      "verbe, sujet, objet :  achetait -> il -> morceau\n",
      "objet complet :  un morceau de dinde ou un morceau d‚Äô oie de douze\n",
      "Phrase compl√©te :  Quand Florent rentrait trop tard pour faire cuire quelque bout de viande, il achetait en bas un morceau de dinde ou un morceau d‚Äôoie de douze sous.\n",
      "\n",
      "verbe, sujet, objet :  vendu -> Il -> mobilier\n",
      "objet complet :  le pauvre mobilier de la rue\n",
      "Phrase compl√©te :  Il avait vendu le pauvre mobilier de la rue Royer-Collard, et en gardait l‚Äôargent, quarante et quelques francs, pour que ce farceur de Quenu, disait-il, ne le jet√¢t pas par les fen√™tres.\n",
      "\n",
      "verbe, sujet, objet :  vendu -> v√©rit√© -> r√¥tisserie\n",
      "objet complet :  la r√¥tisserie\n",
      "Phrase compl√©te :  La v√©rit√© fut qu‚Äôapr√®s avoir vendu la r√¥tisserie, il v√©cut de ses rentes pendant un an.\n",
      "\n",
      "verbe, sujet, objet :  vendait -> elle -> o√π\n",
      "objet complet :  o√π\n",
      "Phrase compl√©te :  Lorsqu‚Äôelle le vit s‚Äô√©tablir aux Halles, √† deux pas du pavillon o√π elle vendait du beurre, des fromages et des ≈ìufs, elle l‚Äôaccusa d‚Äôavoir ¬´ invent√© √ßa pour la taquiner et lui porter mauvaise chance.\n",
      "\n",
      "verbe, sujet, objet :  achetez -> -vous -> morceau\n",
      "objet complet :  un morceau de petit sal√©\n",
      "Phrase compl√©te :  Pourquoi n‚Äôachetez-vous pas un morceau de petit sal√© ?\n",
      "\n",
      "verbe, sujet, objet :  achet√© -> Je -> vous\n",
      "objet complet :  vous\n",
      "Phrase compl√©te :  Je vous en ai achet√© avant-hier, du boudin‚Ä¶\n",
      "\n",
      "verbe, sujet, objet :  achet√© -> Je -> en\n",
      "objet complet :  en\n",
      "Phrase compl√©te :  Je vous en ai achet√© avant-hier, du boudin‚Ä¶\n",
      "\n",
      "verbe, sujet, objet :  vendu -> vous -> paire\n",
      "objet complet :  cette paire de soles\n",
      "Phrase compl√©te :  et, d‚Äôune voix un peu rauque :\n",
      "\n",
      "‚Äî Dites donc, la semaine derni√®re, quand vous m‚Äôavez vendu cette paire de soles, vous savez, est-ce que je suis all√©e vous dire qu‚Äôelles √©taient pourries devant le monde !\n",
      "\n",
      "‚Äî Pourries !\n",
      "\n",
      "verbe, sujet, objet :  vendu -> m‚Äô -> paire\n",
      "objet complet :  cette paire de soles\n",
      "Phrase compl√©te :  et, d‚Äôune voix un peu rauque :\n",
      "\n",
      "‚Äî Dites donc, la semaine derni√®re, quand vous m‚Äôavez vendu cette paire de soles, vous savez, est-ce que je suis all√©e vous dire qu‚Äôelles √©taient pourries devant le monde !\n",
      "\n",
      "‚Äî Pourries !\n",
      "\n",
      "verbe, sujet, objet :  vendrait -> Il -> semelles\n",
      "objet complet :  des semelles de bottes\n",
      "Phrase compl√©te :  Il vendrait des semelles de bottes pour des paires de soles.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"vendre\",    \n",
    "        \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"vendre\", \"acheter\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"sujet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},  \n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"objet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"obj\", \"iobj\", \"obl\"]}},  \n",
    "    }\n",
    "]\n",
    "\n",
    "# {lemma:/vendre|acheter/} > {dep:nsubj} : {lemma:vendre|acheter} > {dep:/obj|iobj|obl/} \n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for m_id, t_ids in matches:\n",
    "    print(\"verbe, sujet, objet : \", \" -> \".join([doc[t_id].text for t_id in t_ids]))\n",
    "    print(\"objet complet : \", \" \".join([t.text for t in doc[t_ids[2]].subtree]))\n",
    "    print(\"Phrase compl√©te : \", doc[t_ids[0]].sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d1099",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Introduction\n",
    "2. √âtapes de la cha√Æne de traitement\n",
    "3. Extraction d'information\n",
    "4. **Adaptation du mod√®le**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d52b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Entit√©s nomm√©es : entra√Ænement\n",
    "\n",
    "- La taille et la nature du corpus d'entra√Ænement seront d√©terminantes\n",
    "- Il est possible d'amender un mod√®le existant avec un jeu de donn√©es annot√©es de taille r√©duite\n",
    "\n",
    "- Exemple sur les entit√©s nomm√©es mais la proc√©dure d'entra√Ænement fonctionne pour d'autres niveaux d'annotations (pos, d√©pendance)\n",
    "- Voir la doc : https://spacy.io/usage/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a5393",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Petit exemple avec des extraits de la page Wikipedia https://fr.wikipedia.org/wiki/Personnages_de_Mario  \n",
    "\n",
    "- Nous conservons le tagset utilis√©s dans le fran√ßais (LOC, MISC, ORG, PER)\n",
    "\n",
    "Nous travaillerons sur 5 petits fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b92bd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luigi.txt mario.txt peach.txt toad.txt  yoshi.txt\n"
     ]
    }
   ],
   "source": [
    "!ls txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b630bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yoshi est un dinosaure ami de Mario. Il peut attraper des objets √©loign√©s gr√¢ce √† sa longue langue et les avaler pour ensuite pondre des ≈ìufs. Comme Toad, son esp√®ce existe en plusieurs couleurs : bleu clair, bleu fonc√©, rose, violet, vert, jaune, noir, blanc et rouge. On peut le remarquer √©galement gr√¢ce √† son gros nez. Il est apparu pour la premi√®re fois dans Super Mario World en 1990, et est le personnage principal de la s√©rie Yoshi's Island o√π il doit sauver B√©b√© Luigi, reprendre des fruits vol√©s, r√©cup√©rer des pelotes‚Ä¶ \n",
      "\u001b[K\u001b[?1l\u001b>shi.txt (END)\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!more txt/yoshi.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a78f7e26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yoshi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " est un dinosaure ami de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mario\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". Il peut attraper des objets √©loign√©s gr√¢ce √† sa longue langue et les avaler pour ensuite pondre des ≈ìufs. Comme \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Toad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", son esp√®ce existe en plusieurs couleurs : bleu clair, bleu fonc√©, rose, violet, vert, jaune, noir, blanc et rouge. On peut le remarquer √©galement gr√¢ce √† son gros nez. Il est apparu pour la premi√®re fois dans \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Super Mario World\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " en 1990, et est le personnage principal de la s√©rie \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yoshi's Island\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " o√π il doit sauver \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    B√©b√© Luigi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", reprendre des fruits vol√©s, r√©cup√©rer des pelotes‚Ä¶ <br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "with open('txt/yoshi.txt') as input:\n",
    "    content = input.read()\n",
    "    doc = nlp(content)\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17022c6a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ces fichiers doivent √™tre tokeniz√©s puis annot√©s au format BIO. Voir l'exemple https://github.com/explosion/spaCy/blob/master/extra/example_data/ner_example_data/ner-token-per-line.iob\n",
    "\n",
    "- Puis les fichiers seront convertis √† l'aide de la commande `convert` (https://spacy.io/api/cli#convert).  \n",
    "Exemple‚ÄØ:  \n",
    "`python -m spacy convert dev_conll/yoshi.conll dev_dir/ --converter ner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39794a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yoshi\tB-PER\n",
      "est\tO\n",
      "un\tO\n",
      "dinosaure\tO\n",
      "ami\tO\n",
      "de\tO\n",
      "Mario\tB-PER\n",
      ".\tO\n",
      "Il\tO\n",
      "peut\tO\n"
     ]
    }
   ],
   "source": [
    "!head dev_conll/yoshi.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e76af14-3c0d-48e9-99c3-f63e306bf804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Auto-detected token-per-line NER format\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No sentence boundaries found to use with option `-n 1`. Use `-s` to\n",
      "automatically segment sentences or `-n 0` to disable.\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No sentence boundaries found. Use `-s` to automatically segment\n",
      "sentences.\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No document delimiters found. Use `-n` to automatically group\n",
      "sentences into documents.\u001b[0m\n",
      "\u001b[38;5;2m‚úî Generated output file (1 documents): dev_dir/yoshi.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert dev_conll/yoshi.conll dev_dir/ --converter ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e0012f80-fe7f-4b8b-b4a3-73dcfb0f1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Auto-detected token-per-line NER format\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No sentence boundaries found to use with option `-n 1`. Use `-s` to\n",
      "automatically segment sentences or `-n 0` to disable.\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No sentence boundaries found. Use `-s` to automatically segment\n",
      "sentences.\u001b[0m\n",
      "\u001b[38;5;3m‚ö† No document delimiters found. Use `-n` to automatically group\n",
      "sentences into documents.\u001b[0m\n",
      "\u001b[38;5;2m‚úî Generated output file (1 documents): train_dir/all.spacy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy convert train_conll/all.conll train_dir/ --converter ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369a987",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Dans la version 3.0, Spacy utilise un fichier de configuration dont le format est d√©fini dans Thinc (https://thinc.ai/docs/usage-config).  \n",
    "Le plus simple est d'utiliser le widget de la doc pour d√©finir les param√®tres principaux : https://spacy.io/usage/training#quickstart\n",
    " \n",
    "- La commande ci-dessous permet de g√©n√©rer votre fichier de configuration : \n",
    " `python -m spacy init fill-config base_config.cfg config.cfg`\n",
    " \n",
    "- Il y a quantit√© de param√®tres √† d√©finir dans ce fichier de config √©videmment. `init` utilise des valeurs par d√©faut qu'on peut modifier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f91fbe39-6188-4030-9863-cca7d80147e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy-transformers\n",
      "  Downloading spacy_transformers-1.3.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy-transformers) (3.7.2)\n",
      "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers)\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy-transformers) (2.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy-transformers) (2.4.8)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers)\n",
      "  Downloading spacy_alignments-0.9.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy-transformers) (1.26.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.3.0)\n",
      "Requirement already satisfied: filelock in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (3.1)\n",
      "Requirement already satisfied: fsspec in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (2023.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers<4.37.0,>=3.4.0->spacy-transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (2023.12.25)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37.0,>=3.4.0->spacy-transformers)\n",
      "  Downloading tokenizers-0.15.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<4.37.0,>=3.4.0->spacy-transformers)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages (from sympy->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
      "Downloading spacy_transformers-1.3.4-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m174.2/174.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy_alignments-0.9.1-cp310-cp310-macosx_11_0_arm64.whl (317 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.3/317.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-macosx_11_0_arm64.whl (393 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m393.4/393.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.1-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: spacy-alignments, safetensors, huggingface-hub, tokenizers, transformers, spacy-transformers\n",
      "Successfully installed huggingface-hub-0.20.3 safetensors-0.4.2 spacy-alignments-0.9.1 spacy-transformers-1.3.4 tokenizers-0.15.1 transformers-4.36.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b62dfbe5-14f3-4a39-a104-a465b9524225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m‚úî Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m‚úî Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668512d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- On peut choisir soit d'entra√Æner un mod√®le ou un des composants du mod√®le *from scratch*, soit de modifier les poids d'un mod√®le existant\n",
    "\n",
    "From scratch : \n",
    "```\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "```\n",
    "\n",
    "Depuis un mod√®le : \n",
    "```\n",
    "[components.ner]\n",
    "source = \"fr_core_news_md\"    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9254a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'entra√Ænement √† proprement parler se fait en ligne de commande :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1550b6af-1bc8-4bcd-83cd-26023c4fa7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m‚úî Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         368.82    545.69    5.17    2.73   50.00    0.05\n",
      "200     200      152914.92  51512.13   42.86   37.50   50.00    0.43\n",
      "400     400      108230.08   7134.02   57.14   50.00   66.67    0.57\n",
      "600     600          34.20     28.12   57.14   50.00   66.67    0.57\n",
      "800     800           3.58      0.67   57.14   50.00   66.67    0.57\n",
      "1000    1000           0.02      0.01   57.14   50.00   66.67    0.57\n",
      "1200    1200           0.01      0.00   57.14   50.00   66.67    0.57\n",
      "1400    1400           0.00      0.00   57.14   50.00   66.67    0.57\n",
      "1600    1600           0.00      0.00   57.14   50.00   66.67    0.57\n",
      "1800    1800           0.00      0.00   57.14   50.00   66.67    0.57\n",
      "2000    2000           0.00      0.00   57.14   50.00   66.67    0.57\n",
      "\u001b[38;5;2m‚úî Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train_dir/all.spacy --paths.dev ./dev_dir/yoshi.spacy --gpu-id 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cfa59",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spacy propose √©galement un outil d'√©valuation qui vous permettra de comparer les performances des mod√®les que vous avez g√©n√©r√©. Les m√©triques sont choisies en fonction du/des types d'annotations du mod√®le. Pour les entit√©s nomm√©es on a : Pr√©cision, Rappel, F-Mesure.\n",
    "  \n",
    "`python -m spacy evaluate model/model-best/ dev_corpus/yoshi.spacy`\n",
    "\n",
    "`python -m spacy evaluate fr_core_news_md dev_corpus/yoshi.spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1a49329",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK      -    \n",
      "TAG      0.00 \n",
      "POS      -    \n",
      "MORPH    -    \n",
      "LEMMA    -    \n",
      "UAS      -    \n",
      "LAS      -    \n",
      "NER P    66.67\n",
      "NER R    66.67\n",
      "NER F    66.67\n",
      "SENT P   0.00 \n",
      "SENT R   0.00 \n",
      "SENT F   0.00 \n",
      "SPEED    3834 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "            P        R       F\n",
      "MISC    66.67   100.00   80.00\n",
      "PER    100.00    50.00   66.67\n",
      "ORG      0.00     0.00    0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate fr_core_news_md dev_dir/yoshi.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d951095e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     -    \n",
      "NER P   50.00\n",
      "NER R   66.67\n",
      "NER F   57.14\n",
      "SPEED   419  \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "            P       R       F\n",
      "PER     42.86   75.00   54.55\n",
      "MISC   100.00   50.00   66.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate output/model-best dev_dir/yoshi.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "19eb028d-8cf3-439c-acc3-cbd1366686ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrejaumier/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy_transformers\n",
    "nlp = spacy.load('output/model-best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "29c567a9",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yoshi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " est un dinosaure ami de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mario\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". Il peut attraper des objets √©loign√©s gr√¢ce √† sa longue langue et les avaler pour ensuite pondre des ≈ìufs. Comme \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Toad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", son esp√®ce existe en plusieurs couleurs : bleu clair, bleu fonc√©, rose, violet, vert, jaune, noir, blanc et rouge. On peut le remarquer √©galement gr√¢ce √† son gros nez. Il est apparu pour la premi√®re fois dans \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Super Mario World\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " en 1990, et est le personnage principal de la s√©rie \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Yoshi's Island\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " o√π il doit sauver \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    B√©b√©\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Luigi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", reprendre des fruits vol√©s, r√©cup√©rer des pelotes‚Ä¶ <br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nlp = spacy.load('output/model-best')\n",
    "\n",
    "with open('txt/yoshi.txt') as input:\n",
    "    content = input.read()\n",
    "    doc = nlp(content)\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc255a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "spaCy pr√©voit les m√©canismes d'export et import des mod√®les et des donn√©es : https://spacy.io/usage/saving-loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1caf73e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merci !\n",
    "\n",
    "Dans l'ordre :\n",
    "- Jeanne Mas, Toute premi√®re fois, 1984\n",
    "- Luna Parker, Tes √©tats d'√¢me‚Ä¶ √âric, 1987\n",
    "- Corynne Charby, Boule de flipper, 1987\n",
    "- Viktor Lazlo, Cano√´ Rose, 1985\n",
    "- Indochine, L'aventurier, 1982\n",
    "- Philip Lavil, Il tape sur des bambous, 1986\n",
    "- Rita Mistuko, Les histoires d'A, 1987"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "rise": {
   "autolaunch": true,
   "theme": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
